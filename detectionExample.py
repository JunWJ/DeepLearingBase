import numpy as np
import matplotlib.pyplot as plt
import platform
from pathlib import Path
from typing import Tuple, List, Dict, Optional
import os
import argparse  # æ–°å¢ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torch.optim.lr_scheduler import CosineAnnealingLR
from PIL import Image
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report
import seaborn as sns
import time

# ===================== å…¨å±€é…ç½®ï¼ˆæ”¯æŒåŠ¨æ€ä¿®æ”¹epochï¼‰=====================
class Config:
    def __init__(self, epochs=50):  # æ–°å¢epochså‚æ•°ï¼Œæ”¯æŒåŠ¨æ€ä¼ å…¥
        # ç›¸å¯¹è·¯å¾„æ ¸å¿ƒï¼šåŸºäºå½“å‰è„šæœ¬å®šä½é¡¹ç›®æ ¹ç›®å½•
        self.SCRIPT_PATH = Path(__file__).resolve()  # å½“å‰è„šæœ¬ç»å¯¹è·¯å¾„
        self.PROJECT_ROOT = self.SCRIPT_PATH.parent  # é¡¹ç›®æ ¹ç›®å½•ï¼ˆè„šæœ¬æ‰€åœ¨ç›®å½•ï¼‰

        # æ•°æ®è·¯å¾„ï¼ˆä»…train/valï¼Œæ— testï¼‰
        self.DATA_ROOT = self.PROJECT_ROOT / "resources" / "detection_data"
        self.TRAIN_PATH = self.DATA_ROOT / "train"
        self.VAL_PATH = self.DATA_ROOT / "val"
        self.ROOT_SAVE_DIR = self.PROJECT_ROOT / "results" / "detection"

        # ç»“æœä¿å­˜è·¯å¾„ï¼ˆæ–°å¢è®­ç»ƒçŠ¶æ€ä¿å­˜è·¯å¾„ï¼‰
        self.BEST_MODEL_PATH = self.ROOT_SAVE_DIR / "best_model.pth"
        self.TRAIN_STATE_PATH = self.ROOT_SAVE_DIR / "train_state.pth"  # æ–­ç‚¹ç»­è®­çŠ¶æ€
        self.LOSS_PLOT_PATH = self.ROOT_SAVE_DIR / "loss_curve.png"
        self.CONFUSION_MATRIX_PATH = self.ROOT_SAVE_DIR / "confusion_matrix.png"

        # æ•°æ®é…ç½®
        self.CLASS_NAMES = ["Cr", "In", "Pa", "PS", "Rs", "Sc"]  # 6ç±»ç¼ºé™·ï¼ˆä¸æ–‡ä»¶å¤¹åä¸€è‡´ï¼‰
        self.NUM_CLASSES = len(self.CLASS_NAMES)
        self.IMG_HEIGHT = 32
        self.IMG_WIDTH = 32
        self.IMAGE_CHANNELS = 3  # RGB=3/ç°åº¦å›¾=1
        self.BATCH_SIZE = 128
        self.NUM_WORKERS = 0 if platform.system() == "Windows" else 4  # Windowsç¦ç”¨å¤šçº¿ç¨‹
        self.USE_AUGMENTATION = True
        self.NORMALIZE_MEAN = [0.485, 0.456, 0.406] if self.IMAGE_CHANNELS == 3 else [0.5]
        self.NORMALIZE_STD = [0.229, 0.224, 0.225] if self.IMAGE_CHANNELS == 3 else [0.5]

        # æ¨¡å‹é…ç½®
        self.DROPOUT_RATE = 0.2

        # è®­ç»ƒé…ç½®ï¼ˆå…³é”®ä¿®æ”¹ï¼šä»å‚æ•°ä¼ å…¥epochsï¼Œä¸å†ç¡¬ç¼–ç ï¼‰
        self.EPOCHS = epochs  # åŠ¨æ€å€¼ï¼Œæ”¯æŒå¤–éƒ¨ä¿®æ”¹
        self.LEARNING_RATE = 1e-4
        self.WEIGHT_DECAY = 1e-5
        self.DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.EARLY_STOPPING_PATIENCE = 10
        self.MONITOR_METRIC = "val_f1"
        self.SEED = 42

        # åˆå§‹åŒ–æ“ä½œ
        self._create_dirs()
        self._set_seed()
        self._setup_chinese_font()
        self._validate_paths()  # éªŒè¯train/valè·¯å¾„æ˜¯å¦å­˜åœ¨

    def _create_dirs(self):
        """åˆ›å»ºç»“æœç›®å½•"""
        self.ROOT_SAVE_DIR.mkdir(parents=True, exist_ok=True)
        print(f"âœ… ç»“æœç›®å½•åˆ›å»ºå®Œæˆï¼š{self.ROOT_SAVE_DIR}")

    def _set_seed(self):
        """å›ºå®šéšæœºç§å­"""
        import random
        random.seed(self.SEED)
        np.random.seed(self.SEED)
        torch.manual_seed(self.SEED)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(self.SEED)
            torch.cuda.manual_seed_all(self.SEED)
        torch.backends.cudnn.deterministic = True
        print(f"âœ… éšæœºç§å­å›ºå®šï¼š{self.SEED}")

    def _setup_chinese_font(self):
        """é…ç½®ä¸­æ–‡å­—ä½“"""
        try:
            system = platform.system()
            font_map = {
                "Windows": ['Microsoft YaHei', 'SimHei'],
                "Linux": ['WenQuanYi Zen Hei'],
                "Darwin": ['Arial Unicode MS']
            }
            plt.rcParams['font.sans-serif'] = font_map.get(system, ['DejaVu Sans'])
            plt.rcParams['axes.unicode_minus'] = False
            print("âœ… ä¸­æ–‡å­—ä½“é…ç½®æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  ä¸­æ–‡å­—ä½“é…ç½®å¤±è´¥ï¼š{str(e)[:30]}")

    def _validate_paths(self):
        """éªŒè¯train/valè·¯å¾„æ˜¯å¦å­˜åœ¨ï¼ˆæ ¸å¿ƒæ£€æŸ¥ï¼‰"""
        required_paths = [self.TRAIN_PATH, self.VAL_PATH]
        for path in required_paths:
            if not path.exists():
                raise FileNotFoundError(f"âŒ å…³é”®æ•°æ®è·¯å¾„ä¸å­˜åœ¨ï¼š{path}\nè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼")
        print(f"\nğŸ“Œ è·¯å¾„éªŒè¯é€šè¿‡ï¼š")
        print(f"è®­ç»ƒé›†è·¯å¾„ï¼š{self.TRAIN_PATH}")
        print(f"éªŒè¯é›†è·¯å¾„ï¼š{self.VAL_PATH}")

# ===================== æ•°æ®é›†ç±»ï¼ˆå…¼å®¹ä¸¤ç§ç›®å½•ç»“æ„ï¼‰=====================
class DefectDataset(Dataset):
    def __init__(self, data_dir: Path, class_to_idx: Dict[str, int], transform=None, image_channels: int = 3):
        self.data_dir = data_dir
        self.class_to_idx = class_to_idx
        self.transform = transform
        self.image_channels = image_channels
        self.image_paths, self.labels = self._load_data()

        # å…³é”®æ£€æŸ¥ï¼šç¡®ä¿åŠ è½½åˆ°æ•°æ®
        if len(self.image_paths) == 0:
            raise ValueError(f"âŒ åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶ï¼\nè¯·æ£€æŸ¥ï¼š1.å›¾åƒæ ¼å¼ï¼ˆjpg/png/bmpç­‰ï¼‰2.æ˜¯å¦æŒ‰ç±»åˆ«åˆ†æ–‡ä»¶å¤¹")

    def _load_data(self) -> Tuple[list, list]:
        """åŠ è½½æŒ‰ç±»åˆ«åˆ†æ–‡ä»¶å¤¹çš„å›¾åƒï¼ˆæ¨èç»“æ„ï¼štrain/Cr/xxx.jpgï¼‰"""
        image_paths, labels = [], []
        for cls_name, cls_idx in self.class_to_idx.items():
            cls_dir = self.data_dir / cls_name
            if not cls_dir.exists():
                print(f"âš ï¸  ç±»åˆ«æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼š{cls_dir}ï¼ˆè·³è¿‡è¯¥ç±»åˆ«ï¼‰")
                continue
            # æ”¯æŒå¤šç§å›¾åƒæ ¼å¼
            for ext in ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.tif"]:
                cls_images = list(cls_dir.glob(ext))
                if cls_images:
                    image_paths.extend([str(p) for p in cls_images])
                    labels.extend([cls_idx] * len(cls_images))
        return image_paths, labels

    def __len__(self) -> int:
        return len(self.image_paths)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        """è¯»å–å•å¼ å›¾åƒå¹¶è¿”å›ï¼ˆimage, labelï¼‰"""
        img_path = self.image_paths[idx]
        try:
            # æ ¹æ®é€šé“æ•°é€‰æ‹©å›¾åƒæ¨¡å¼ï¼ˆRGB/ç°åº¦ï¼‰
            mode = "RGB" if self.image_channels == 3 else "L"
            image = Image.open(img_path).convert(mode)
            if self.transform:
                image = self.transform(image)
            return image, self.labels[idx]
        except Exception as e:
            raise RuntimeError(f"âŒ è¯»å–å›¾åƒå¤±è´¥ï¼š{img_path}\né”™è¯¯åŸå› ï¼š{str(e)}")

# ===================== æ•°æ®åŠ è½½å‡½æ•°ï¼ˆæ— testé›†ï¼Œè¿”å›train/val_loaderï¼‰=====================
def create_dataloaders(config: Config) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """åˆ›å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•DataLoaderï¼ˆæµ‹è¯•é›†ç”¨valé›†æ›¿ä»£ï¼‰"""
    class_to_idx = {cls: idx for idx, cls in enumerate(config.CLASS_NAMES)}

    # è®­ç»ƒé›†å˜æ¢ï¼ˆå«æ•°æ®å¢å¼ºï¼‰
    train_transform = transforms.Compose([
        transforms.Resize((config.IMG_HEIGHT, config.IMG_WIDTH)),
        transforms.RandomHorizontalFlip(p=0.3),
        transforms.RandomRotation(degrees=(-5, 5)),  # è½»å¾®æ—‹è½¬ï¼Œé¿å…è¿‡åº¦å¢å¼º
        transforms.ToTensor(),
        transforms.Normalize(config.NORMALIZE_MEAN, config.NORMALIZE_STD)
    ]) if config.USE_AUGMENTATION else transforms.Compose([
        transforms.Resize((config.IMG_HEIGHT, config.IMG_WIDTH)),
        transforms.ToTensor(),
        transforms.Normalize(config.NORMALIZE_MEAN, config.NORMALIZE_STD)
    ])

    # éªŒè¯é›†/æµ‹è¯•é›†å˜æ¢ï¼ˆæ— å¢å¼ºï¼Œä»…å½’ä¸€åŒ–ï¼‰
    val_test_transform = transforms.Compose([
        transforms.Resize((config.IMG_HEIGHT, config.IMG_WIDTH)),
        transforms.ToTensor(),
        transforms.Normalize(config.NORMALIZE_MEAN, config.NORMALIZE_STD)
    ])

    # åˆ›å»ºæ•°æ®é›†
    train_dataset = DefectDataset(config.TRAIN_PATH, class_to_idx, train_transform, config.IMAGE_CHANNELS)
    val_dataset = DefectDataset(config.VAL_PATH, class_to_idx, val_test_transform, config.IMAGE_CHANNELS)
    test_dataset = val_dataset  # ğŸ”¥ æ— testé›†ï¼šç”¨valé›†æ›¿ä»£æµ‹è¯•é›†

    # åˆ›å»ºDataLoaderï¼ˆWindowså¼ºåˆ¶num_workers=0ï¼‰
    train_loader = DataLoader(
        train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,
        num_workers=0, pin_memory=True, drop_last=False
    )
    val_loader = DataLoader(
        val_dataset, batch_size=config.BATCH_SIZE, shuffle=False,
        num_workers=0, pin_memory=True, drop_last=False
    )
    test_loader = DataLoader(
        test_dataset, batch_size=config.BATCH_SIZE, shuffle=False,
        num_workers=0, pin_memory=True, drop_last=False
    )

    # æ‰“å°æ•°æ®åŠ è½½ä¿¡æ¯
    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆï¼š")
    print(f"è®­ç»ƒé›†ï¼š{len(train_dataset)} æ ·æœ¬")
    print(f"éªŒè¯é›†ï¼š{len(val_dataset)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†ï¼šä½¿ç”¨éªŒè¯é›†æ›¿ä»£ï¼ˆ{len(test_dataset)} æ ·æœ¬ï¼‰")
    return train_loader, val_loader, test_loader

# ===================== CNNæ¨¡å‹ï¼ˆè½»é‡å‹ï¼Œé€‚é…å°å›¾åƒï¼‰=====================
class DefectCNN(nn.Module):
    def __init__(self, config: Config):
        super().__init__()
        in_channels = config.IMAGE_CHANNELS
        num_classes = config.NUM_CLASSES
        dropout = config.DROPOUT_RATE

        # å·ç§¯ç‰¹å¾æå–ï¼ˆ32x32â†’4x4ï¼‰
        self.conv_layers = nn.Sequential(
            nn.Conv2d(in_channels, 16, 3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 32â†’16

            nn.Conv2d(16, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 16â†’8

            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)  # 8â†’4
        )

        # åˆ†ç±»å¤´ï¼ˆå…¨è¿æ¥å±‚ï¼‰
        self.fc_layers = nn.Sequential(
            nn.Flatten(),  # 64*4*4 = 1024
            nn.Linear(64 * 4 * 4, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x

# ===================== å·¥å…·å‡½æ•°ï¼ˆæŒ‡æ ‡è®¡ç®—+å¯è§†åŒ–ï¼‰=====================
def calculate_metrics(outputs: torch.Tensor, labels: torch.Tensor) -> Tuple[float, float]:
    """è®¡ç®—å‡†ç¡®ç‡å’ŒF1åˆ†æ•°"""
    preds = torch.argmax(outputs, dim=1).cpu().numpy()
    labels = labels.cpu().numpy()
    return accuracy_score(labels, preds), f1_score(labels, preds, average="macro")

def plot_curves(train_losses: List[float], val_losses: List[float],
                train_accs: List[float], val_accs: List[float],
                train_f1s: List[float], val_f1s: List[float], save_path: Path):
    """ç»˜åˆ¶æŸå¤±å’ŒæŒ‡æ ‡æ›²çº¿"""
    epochs = range(1, len(train_losses) + 1)
    plt.figure(figsize=(12, 4))

    # æŸå¤±æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, label="è®­ç»ƒæŸå¤±", marker="o", markersize=4)
    plt.plot(epochs, val_losses, label="éªŒè¯æŸå¤±", marker="s", markersize=4)
    plt.xlabel("è®­ç»ƒè½®æ•°ï¼ˆEpochï¼‰")
    plt.ylabel("æŸå¤±å€¼")
    plt.legend()
    plt.grid(alpha=0.3)

    # æŒ‡æ ‡æ›²çº¿ï¼ˆå‡†ç¡®ç‡+F1ï¼‰
    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_accs, label="è®­ç»ƒå‡†ç¡®ç‡", marker="o", markersize=4)
    plt.plot(epochs, val_accs, label="éªŒè¯å‡†ç¡®ç‡", marker="s", markersize=4)
    plt.plot(epochs, train_f1s, label="è®­ç»ƒF1åˆ†æ•°", marker="^", markersize=4)
    plt.plot(epochs, val_f1s, label="éªŒè¯F1åˆ†æ•°", marker="d", markersize=4)
    plt.xlabel("è®­ç»ƒè½®æ•°ï¼ˆEpochï¼‰")
    plt.ylabel("æŒ‡æ ‡å€¼ï¼ˆ0-1ï¼‰")
    plt.legend()
    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    plt.show()
    print(f"âœ… æŸå¤±/æŒ‡æ ‡æ›²çº¿å·²ä¿å­˜ï¼š{save_path}")

def plot_confusion_matrix(labels: np.ndarray, preds: np.ndarray, class_names: List[str], save_path: Path):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼ˆåŸºäºéªŒè¯é›†ï¼Œå› æ— testé›†ï¼‰"""
    cm = confusion_matrix(labels, preds)
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        cm, annot=True, fmt="d", cmap="Blues",
        xticklabels=class_names, yticklabels=class_names,
        annot_kws={"fontsize": 10}
    )
    plt.xlabel("é¢„æµ‹ç±»åˆ«", fontsize=12)
    plt.ylabel("çœŸå®ç±»åˆ«", fontsize=12)
    plt.title("ç¼ºé™·æ£€æµ‹æ··æ·†çŸ©é˜µï¼ˆéªŒè¯é›†ï¼‰", fontsize=14, fontweight="bold")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    plt.show()
    print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜ï¼š{save_path}")

# ===================== è®­ç»ƒæµç¨‹ï¼ˆæ”¯æŒåŠ¨æ€epoch+æ–­ç‚¹ç»­è®­ï¼‰=====================
def train_model(config: Config, model: nn.Module, train_loader: DataLoader, val_loader: DataLoader):
    """è®­ç»ƒæ¨¡å‹ï¼ˆå«æ—©åœã€æœ€ä½³æ¨¡å‹ä¿å­˜ã€æ–­ç‚¹ç»­è®­ï¼‰"""
    # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
    model = model.to(config.DEVICE)
    criterion = nn.CrossEntropyLoss()  # å¤šåˆ†ç±»æŸå¤±
    
    # ä¼˜åŒ–å™¨ä½¿ç”¨åŠ¨æ€é…ç½®çš„è¶…å‚æ•°
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.LEARNING_RATE,
        weight_decay=config.WEIGHT_DECAY
    )
    # è°ƒåº¦å™¨ä½¿ç”¨åŠ¨æ€çš„EPOCHSå€¼
    scheduler = CosineAnnealingLR(optimizer, T_max=config.EPOCHS, eta_min=1e-6)

    # ========== æ–­ç‚¹ç»­è®­æ ¸å¿ƒé€»è¾‘ ==========
    start_epoch = 0
    best_metric = 0.0
    early_stop_counter = 0
    # è®­ç»ƒè®°å½•åˆå§‹åŒ–
    train_losses, val_losses = [], []
    train_accs, val_accs = [], []
    train_f1s, val_f1s = [], []

    # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„è®­ç»ƒçŠ¶æ€
    if config.TRAIN_STATE_PATH.exists():
        print(f"\nğŸ”„ å‘ç°æ–­ç‚¹ç»­è®­æ–‡ä»¶ï¼š{config.TRAIN_STATE_PATH}")
        # åŠ è½½è®­ç»ƒçŠ¶æ€ï¼ˆå…ˆåŠ è½½åˆ°CPUï¼Œå†è¿ç§»åˆ°ç›®æ ‡è®¾å¤‡ï¼‰
        checkpoint = torch.load(config.TRAIN_STATE_PATH, map_location='cpu')
        
        # 1. åŠ è½½æ¨¡å‹æƒé‡ï¼ˆç¡®ä¿åœ¨ç›®æ ‡è®¾å¤‡ï¼‰
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(config.DEVICE)
        
        # 2. é‡æ–°åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼ˆä¿ç•™è¶…å‚æ•°ï¼‰
        optimizer = optim.AdamW(
            model.parameters(),
            lr=checkpoint.get('lr', config.LEARNING_RATE),
            weight_decay=checkpoint.get('weight_decay', config.WEIGHT_DECAY)
        )
        
        # 3. é‡æ–°åˆå§‹åŒ–è°ƒåº¦å™¨ï¼ˆä½¿ç”¨æ–°çš„EPOCHSå€¼ï¼‰
        scheduler = CosineAnnealingLR(optimizer, T_max=config.EPOCHS, eta_min=1e-6)
        try:
            # å°è¯•åŠ è½½è°ƒåº¦å™¨çŠ¶æ€ï¼ˆå…¼å®¹æ—§çš„æ–­ç‚¹æ–‡ä»¶ï¼‰
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        except:
            print(f"âš ï¸  è°ƒåº¦å™¨çŠ¶æ€åŠ è½½å¤±è´¥ï¼Œå·²ä½¿ç”¨æ–°çš„epochæ•°ï¼ˆ{config.EPOCHS}ï¼‰é‡æ–°åˆå§‹åŒ–")
        
        # 4. åŠ è½½å…¶ä»–è®­ç»ƒçŠ¶æ€
        start_epoch = checkpoint['epoch'] + 1
        best_metric = checkpoint['best_metric']
        early_stop_counter = checkpoint['early_stop_counter']
        # åŠ è½½å†å²æŒ‡æ ‡
        train_losses = checkpoint['train_losses']
        val_losses = checkpoint['val_losses']
        train_accs = checkpoint['train_accs']
        val_accs = checkpoint['val_accs']
        train_f1s = checkpoint['train_f1s']
        val_f1s = checkpoint['val_f1s']

        print(f"âœ… æˆåŠŸåŠ è½½æ–­ç‚¹çŠ¶æ€ï¼š")
        print(f"  - ä¸Šæ¬¡è®­ç»ƒåˆ°ç¬¬ {checkpoint['epoch']} è½®")
        print(f"  - æœ¬æ¬¡è®­ç»ƒæ€»è½®æ•°ï¼š{config.EPOCHS}ï¼ˆä»{start_epoch}å¼€å§‹ï¼‰")
        print(f"  - æœ€ä½³{config.MONITOR_METRIC}ï¼š{best_metric:.4f}")
        print(f"  - æ—©åœè®¡æ•°å™¨ï¼š{early_stop_counter}/{config.EARLY_STOPPING_PATIENCE}")
    else:
        print(f"\nğŸš€ æœªå‘ç°æ–­ç‚¹æ–‡ä»¶ï¼Œå¼€å§‹å…¨æ–°è®­ç»ƒï¼ˆæ€»è½®æ•°ï¼š{config.EPOCHS}ï¼‰")

    print("\n" + "="*60 + " å¼€å§‹è®­ç»ƒ " + "="*60 + "\n")
    start_time = time.time()

    # å…³é”®ä¿®æ”¹ï¼šå¾ªç¯ä¸Šé™æ˜¯config.EPOCHSï¼ˆåŠ¨æ€å€¼ï¼‰
    for epoch in range(start_epoch, config.EPOCHS):
        # ---------------------- è®­ç»ƒé˜¶æ®µ ----------------------
        model.train()
        train_total_loss = 0.0
        train_all_preds, train_all_labels = [], []

        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(config.DEVICE), labels.to(config.DEVICE)

            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, labels)

            # åå‘ä¼ æ’­+ä¼˜åŒ–
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # ç´¯è®¡æŸå¤±å’Œé¢„æµ‹ç»“æœ
            train_total_loss += loss.item() * images.size(0)
            train_all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())
            train_all_labels.extend(labels.cpu().numpy())

            # æ‰“å°æ‰¹æ¬¡æ—¥å¿—ï¼ˆæ¯10ä¸ªbatchæ‰“å°ä¸€æ¬¡ï¼‰
            if (batch_idx + 1) % 10 == 0:
                batch_acc = accuracy_score(labels.cpu().numpy(), torch.argmax(outputs, dim=1).cpu().numpy())
                print(f"Epoch [{epoch+1}/{config.EPOCHS}] | Batch [{batch_idx+1}/{len(train_loader)}] | "
                      f"Loss: {loss.item():.4f} | Acc: {batch_acc:.4f}")

        # è®¡ç®—è®­ç»ƒé›†æŒ‡æ ‡
        train_avg_loss = train_total_loss / len(train_loader.dataset)
        train_acc = accuracy_score(train_all_labels, train_all_preds)
        train_f1 = f1_score(train_all_labels, train_all_preds, average="macro")

        # ---------------------- éªŒè¯é˜¶æ®µ ----------------------
        model.eval()
        val_total_loss = 0.0
        val_all_preds, val_all_labels = [], []

        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒåŠ é€ŸéªŒè¯
            for images, labels in val_loader:
                images, labels = images.to(config.DEVICE), labels.to(config.DEVICE)
                outputs = model(images)
                loss = criterion(outputs, labels)

                val_total_loss += loss.item() * images.size(0)
                val_all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())
                val_all_labels.extend(labels.cpu().numpy())

        # è®¡ç®—éªŒè¯é›†æŒ‡æ ‡
        val_avg_loss = val_total_loss / len(val_loader.dataset)
        val_acc = accuracy_score(val_all_labels, val_all_preds)
        val_f1 = f1_score(val_all_labels, val_all_preds, average="macro")

        # ---------------------- è®°å½•ä¸ä¿å­˜ ----------------------
        # ä¿å­˜æŒ‡æ ‡
        train_losses.append(train_avg_loss)
        val_losses.append(val_avg_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)
        train_f1s.append(train_f1)
        val_f1s.append(val_f1)

        # æ‰“å°è½®æ¬¡æ—¥å¿—
        print(f"\nğŸ“Š Epoch [{epoch+1}/{config.EPOCHS}] æ€»ç»“ï¼š")
        print(f"è®­ç»ƒé›† - æŸå¤±ï¼š{train_avg_loss:.4f} | å‡†ç¡®ç‡ï¼š{train_acc:.4f} | F1ï¼š{train_f1:.4f}")
        print(f"éªŒè¯é›† - æŸå¤±ï¼š{val_avg_loss:.4f} | å‡†ç¡®ç‡ï¼š{val_acc:.4f} | F1ï¼š{val_f1:.4f}\n")

        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()

        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºç›‘æ§æŒ‡æ ‡ï¼‰
        current_metric = val_f1 if config.MONITOR_METRIC == "val_f1" else val_acc
        if current_metric > best_metric:
            best_metric = current_metric
            torch.save(model.state_dict(), config.BEST_MODEL_PATH)
            print(f"ğŸ† ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆ{config.MONITOR_METRIC}ï¼š{best_metric:.4f}ï¼‰\n")
            early_stop_counter = 0  # é‡ç½®æ—©åœè®¡æ•°å™¨
        else:
            early_stop_counter += 1
            print(f"âš ï¸  æ—©åœè®¡æ•°å™¨ï¼š{early_stop_counter}/{config.EARLY_STOPPING_PATIENCE}\n")
            # æ—©åœè§¦å‘
            if early_stop_counter >= config.EARLY_STOPPING_PATIENCE:
                print(f"âœ… æ—©åœè§¦å‘ï¼éªŒè¯é›†{config.MONITOR_METRIC}å·²{config.EARLY_STOPPING_PATIENCE}è½®æ— æå‡")
                break

        # ========== ä¿å­˜è®­ç»ƒçŠ¶æ€ï¼ˆåŒ…å«å½“å‰epochæ•°ï¼‰ ==========
        train_state = {
            'epoch': epoch,  # å½“å‰è®­ç»ƒåˆ°çš„è½®æ•°
            'model_state_dict': model.state_dict(),  # æ¨¡å‹æƒé‡ï¼ˆæ ¸å¿ƒï¼‰
            'scheduler_state_dict': scheduler.state_dict(),  # è°ƒåº¦å™¨çŠ¶æ€
            'best_metric': best_metric,  # æœ€ä½³æŒ‡æ ‡
            'early_stop_counter': early_stop_counter,  # æ—©åœè®¡æ•°å™¨
            'lr': config.LEARNING_RATE,  # å­¦ä¹ ç‡
            'weight_decay': config.WEIGHT_DECAY,  # æƒé‡è¡°å‡
            'total_epochs': config.EPOCHS,  # æ–°å¢ï¼šè®°å½•æœ¬æ¬¡è®­ç»ƒçš„æ€»è½®æ•°
            # å†å²æŒ‡æ ‡è®°å½•
            'train_losses': train_losses,
            'val_losses': val_losses,
            'train_accs': train_accs,
            'val_accs': val_accs,
            'train_f1s': train_f1s,
            'val_f1s': val_f1s
        }
        # ä¿å­˜åˆ°CPUï¼Œé¿å…CUDAå¼ é‡é—®é¢˜
        torch.save(train_state, config.TRAIN_STATE_PATH)
        print(f"ğŸ’¾ å·²ä¿å­˜è®­ç»ƒçŠ¶æ€ï¼š{config.TRAIN_STATE_PATH}\n")

    # è®­ç»ƒç»“æŸï¼šç»˜åˆ¶æ›²çº¿
    total_train_time = (time.time() - start_time) / 60
    print(f"\n" + "="*60 + " è®­ç»ƒå®Œæˆ " + "="*60)
    print(f"æ€»è®­ç»ƒæ—¶é—´ï¼š{total_train_time:.2f} åˆ†é’Ÿ")
    print(f"å®é™…è®­ç»ƒè½®æ•°ï¼š{epoch+1 - start_epoch}ï¼ˆä»{start_epoch}åˆ°{epoch+1}ï¼‰")
    print(f"æœ€ä½³{config.MONITOR_METRIC}ï¼š{best_metric:.4f}")
    print(f"æœ€ä½³æ¨¡å‹è·¯å¾„ï¼š{config.BEST_MODEL_PATH}")
    plot_curves(train_losses, val_losses, train_accs, val_accs, train_f1s, val_f1s, config.LOSS_PLOT_PATH)

# ===================== æµ‹è¯•æµç¨‹ï¼ˆç”¨valé›†æ›¿ä»£testé›†ï¼‰=====================
def test_model(config: Config, model: nn.Module, test_loader: DataLoader):
    """æµ‹è¯•æ¨¡å‹ï¼ˆåŸºäºéªŒè¯é›†ï¼Œå› æ— testé›†ï¼‰"""
    model = model.to(config.DEVICE)
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if not config.BEST_MODEL_PATH.exists():
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼š{config.BEST_MODEL_PATH}")
    model.load_state_dict(torch.load(config.BEST_MODEL_PATH, map_location=config.DEVICE))
    model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼

    criterion = nn.CrossEntropyLoss()
    test_total_loss = 0.0
    all_preds, all_labels = [], []

    print("\n" + "="*60 + " å¼€å§‹æµ‹è¯•ï¼ˆä½¿ç”¨éªŒè¯é›†æ›¿ä»£ï¼‰ " + "="*60 + "\n")
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(config.DEVICE), labels.to(config.DEVICE)
            outputs = model(images)
            loss = criterion(outputs, labels)

            test_total_loss += loss.item() * images.size(0)
            all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡ï¼ˆé¿å…é™¤é›¶é”™è¯¯ï¼‰
    test_avg_loss = test_total_loss / len(test_loader.dataset)
    test_acc = accuracy_score(all_labels, all_preds)
    test_precision = precision_score(all_labels, all_preds, average="macro", zero_division=0)
    test_recall = recall_score(all_labels, all_preds, average="macro", zero_division=0)
    test_f1 = f1_score(all_labels, all_preds, average="macro", zero_division=0)

    # æ‰“å°æµ‹è¯•ç»“æœ
    print(f"ğŸ“‹ æµ‹è¯•ç»“æœï¼ˆéªŒè¯é›†ï¼‰ï¼š")
    print(f"å¹³å‡æŸå¤±ï¼š{test_avg_loss:.4f}")
    print(f"å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼š{test_acc:.4f}")
    print(f"ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ï¼š{test_precision:.4f}")
    print(f"å¬å›ç‡ï¼ˆRecallï¼‰ï¼š{test_recall:.4f}")
    print(f"F1åˆ†æ•°ï¼ˆF1-Scoreï¼‰ï¼š{test_f1:.4f}\n")

    # æ‰“å°è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    print("ğŸ“‹ åˆ†ç±»è¯¦ç»†æŠ¥å‘Šï¼š")
    print(classification_report(
        all_labels, all_preds,
        target_names=config.CLASS_NAMES,
        digits=4,
        zero_division=0
    ))

    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    plot_confusion_matrix(np.array(all_labels), np.array(all_preds), config.CLASS_NAMES, config.CONFUSION_MATRIX_PATH)

# ===================== å•å¼ å›¾ç‰‡é¢„æµ‹å‡½æ•°=====================
def predict_single_image(
    config: Config,
    model: nn.Module,
    image_path: str or Path,
    show_image: bool = True,
    save_result: bool = True
) -> Dict[str, any]:
    """
    ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹å•å¼ å›¾ç‰‡çš„ç±»åˆ«
    
    å‚æ•°ï¼š
        config: é…ç½®ç±»å®ä¾‹ï¼ˆåŒ…å«ç±»åˆ«åã€å›¾åƒå°ºå¯¸ç­‰ï¼‰
        model: è®­ç»ƒå¥½çš„æ¨¡å‹å®ä¾‹
        image_path: æµ‹è¯•å›¾ç‰‡çš„è·¯å¾„ï¼ˆå­—ç¬¦ä¸²/Pathå¯¹è±¡ï¼‰
        show_image: æ˜¯å¦æ˜¾ç¤ºé¢„æµ‹ç»“æœå›¾ç‰‡ï¼ˆå«ç±»åˆ«+ç½®ä¿¡åº¦ï¼‰
        save_result: æ˜¯å¦ä¿å­˜é¢„æµ‹ç»“æœå›¾ç‰‡åˆ°ç»“æœç›®å½•
    
    è¿”å›ï¼š
        é¢„æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - pred_class: é¢„æµ‹ç±»åˆ«åç§°ï¼ˆå¦‚ "Cr"ï¼‰
            - pred_idx: é¢„æµ‹ç±»åˆ«ç´¢å¼•ï¼ˆ0-5ï¼‰
            - confidence: é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
            - all_confidences: æ‰€æœ‰ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ—è¡¨
            - image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
    """
    # 1. è·¯å¾„æ ¡éªŒ
    image_path = Path(image_path)
    if not image_path.exists():
        raise FileNotFoundError(f"âŒ å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨ï¼š{image_path}")
    
    # 2. æ¨¡å‹å‡†å¤‡ï¼ˆåˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨æ¢¯åº¦ï¼‰
    model = model.to(config.DEVICE)
    model.eval()
    
    # 3. å›¾ç‰‡é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶çš„éªŒè¯é›†é¢„å¤„ç†ä¿æŒä¸€è‡´ï¼‰
    transform = transforms.Compose([
        transforms.Resize((config.IMG_HEIGHT, config.IMG_WIDTH)),
        transforms.ToTensor(),
        transforms.Normalize(config.NORMALIZE_MEAN, config.NORMALIZE_STD)
    ])
    
    try:
        # åŠ è½½å›¾ç‰‡ï¼ˆå…¼å®¹RGB/ç°åº¦ï¼Œä¸è®­ç»ƒæ—¶çš„é€šé“æ•°ä¸€è‡´ï¼‰
        mode = "RGB" if config.IMAGE_CHANNELS == 3 else "L"
        image = Image.open(image_path).convert(mode)
        original_image = image.copy()  # ä¿å­˜åŸå§‹å›¾ç‰‡ç”¨äºå¯è§†åŒ–
    except Exception as e:
        raise RuntimeError(f"âŒ åŠ è½½å›¾ç‰‡å¤±è´¥ï¼š{str(e)}")
    
    # é¢„å¤„ç†å¹¶æ·»åŠ batchç»´åº¦ï¼ˆæ¨¡å‹è¦æ±‚è¾“å…¥æ˜¯[batch, channel, h, w]ï¼‰
    input_tensor = transform(image).unsqueeze(0).to(config.DEVICE)
    
    # 4. æ¨¡å‹æ¨ç†ï¼ˆç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒåŠ é€Ÿæ¨ç†ï¼‰
    with torch.no_grad():
        outputs = model(input_tensor)  # è¾“å‡ºä¸ºlogits
        probabilities = torch.softmax(outputs, dim=1)  # è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆ0-1ï¼‰
        pred_idx = torch.argmax(probabilities, dim=1).item()  # é¢„æµ‹ç±»åˆ«ç´¢å¼•
        pred_confidence = probabilities[0][pred_idx].item()  # é¢„æµ‹ç½®ä¿¡åº¦
        all_confidences = probabilities[0].cpu().numpy().tolist()  # æ‰€æœ‰ç±»åˆ«ç½®ä¿¡åº¦
    
    # 5. ç»“æœè§£æ
    pred_class = config.CLASS_NAMES[pred_idx]
    result = {
        "pred_class": pred_class,
        "pred_idx": pred_idx,
        "confidence": round(pred_confidence, 4),
        "all_confidences": [round(c, 4) for c in all_confidences],
        "image_path": str(image_path)
    }
    
    # 6. æ‰“å°æ¸…æ™°çš„é¢„æµ‹ç»“æœ
    print("\n" + "="*50 + " å•å¼ å›¾ç‰‡é¢„æµ‹ç»“æœ " + "="*50)
    print(f"å›¾ç‰‡è·¯å¾„ï¼š{image_path}")
    print(f"é¢„æµ‹ç±»åˆ«ï¼š{pred_class} (ç´¢å¼•ï¼š{pred_idx})")
    print(f"é¢„æµ‹ç½®ä¿¡åº¦ï¼š{result['confidence'] * 100:.2f}%")
    print("\næ‰€æœ‰ç±»åˆ«ç½®ä¿¡åº¦ï¼š")
    for cls_name, conf in zip(config.CLASS_NAMES, result['all_confidences']):
        print(f"  - {cls_name}: {conf * 100:.2f}%")
    print("="*110 + "\n")
    
    # 7. å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰
    if show_image or save_result:
        plt.figure(figsize=(8, 6))
        plt.imshow(original_image)
        plt.axis('off')  # éšè—åæ ‡è½´
        # æ·»åŠ é¢„æµ‹ç»“æœæ–‡æœ¬
        text = f"é¢„æµ‹ç±»åˆ«ï¼š{pred_class}\nç½®ä¿¡åº¦ï¼š{pred_confidence * 100:.2f}%"
        plt.text(
            10, 10, text, 
            fontsize=12, color='white', 
            bbox=dict(boxstyle="round,pad=0.5", facecolor='red', alpha=0.8)
        )
        plt.title(f"ç¼ºé™·æ£€æµ‹ç»“æœï¼š{pred_class}", fontsize=14, fontweight='bold')
        
        # ä¿å­˜ç»“æœå›¾ç‰‡
        if save_result:
            save_path = config.ROOT_SAVE_DIR / f"single_pred_{image_path.stem}.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… é¢„æµ‹ç»“æœå›¾ç‰‡å·²ä¿å­˜ï¼š{save_path}")
        
        # æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
        if show_image:
            plt.show()
        plt.close()
    
    return result

# ===================== ä¸»å‡½æ•°ï¼ˆæ”¯æŒå‘½ä»¤è¡Œä¼ å‚ä¿®æ”¹epochï¼‰=====================
def main():
    # æ–°å¢ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆä¿ç•™åŸæœ‰å‚æ•°ï¼Œæ–°å¢å•å¼ å›¾ç‰‡æµ‹è¯•å‚æ•°ï¼‰
    parser = argparse.ArgumentParser(description='ç¼ºé™·æ£€æµ‹è®­ç»ƒ/æµ‹è¯•è„šæœ¬')
    parser.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒæ€»è½®æ•°ï¼ˆé»˜è®¤50ï¼‰')
    parser.add_argument('--predict', type=str, default=None, help='å•å¼ å›¾ç‰‡æµ‹è¯•è·¯å¾„ï¼ˆå¦‚ï¼š./test_img.pngï¼‰')
    args = parser.parse_args()

    try:
        # 1. åˆå§‹åŒ–é…ç½®
        config = Config(epochs=args.epochs)
        print(f"\nğŸ“Œ è®­ç»ƒé…ç½®ï¼š")
        print(f"è®¾å¤‡ï¼š{config.DEVICE} | ç±»åˆ«æ•°ï¼š{config.NUM_CLASSES} | æ‰¹æ¬¡å¤§å°ï¼š{config.BATCH_SIZE}")
        print(f"è®­ç»ƒè½®æ•°ï¼š{config.EPOCHS} | å­¦ä¹ ç‡ï¼š{config.LEARNING_RATE}")

        # 2. åˆå§‹åŒ–æ¨¡å‹
        model = DefectCNN(config)
        print(f"\nğŸ“Œ æ¨¡å‹ä¿¡æ¯ï¼š")
        print(f"æ¨¡å‹å‚æ•°æ€»æ•°ï¼š{sum(p.numel() for p in model.parameters()):,}")

        # ====== æ–°å¢ï¼šå•å¼ å›¾ç‰‡æµ‹è¯•é€»è¾‘ ======
        if args.predict:
            # åŠ è½½è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹
            if not config.BEST_MODEL_PATH.exists():
                raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼š{config.BEST_MODEL_PATH}\nè¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼")
            
            # åŠ è½½æ¨¡å‹æƒé‡
            model.load_state_dict(torch.load(config.BEST_MODEL_PATH, map_location=config.DEVICE))
            print(f"âœ… æˆåŠŸåŠ è½½æœ€ä½³æ¨¡å‹ï¼š{config.BEST_MODEL_PATH}")
            
            # è°ƒç”¨å•å¼ å›¾ç‰‡é¢„æµ‹å‡½æ•°
            predict_single_image(
                config=config,
                model=model,
                image_path=args.predict,
                show_image=True,  # æ˜¾ç¤ºå›¾ç‰‡
                save_result=True   # ä¿å­˜ç»“æœ
            )
            return  # ä»…æµ‹è¯•å•å¼ å›¾ç‰‡ï¼Œä¸æ‰§è¡Œè®­ç»ƒ/éªŒè¯é›†æµ‹è¯•
        
        # ====== åŸæœ‰é€»è¾‘ï¼ˆè®­ç»ƒ+éªŒè¯é›†æµ‹è¯•ï¼‰ ======
        # 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = create_dataloaders(config)

        # 4. è®­ç»ƒæ¨¡å‹
        train_model(config, model, train_loader, val_loader)

        # 5. æµ‹è¯•æ¨¡å‹ï¼ˆéªŒè¯é›†ï¼‰
        test_model(config, model, test_loader)

        print("\n" + "="*60 + " æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ " + "="*60)
        print(f"ç»“æœä¿å­˜ç›®å½•ï¼š{config.ROOT_SAVE_DIR}")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™ï¼š{str(e)}")
        raise

if __name__ == "__main__":
    main()